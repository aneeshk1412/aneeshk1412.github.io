<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <style type="text/css">
    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 400
    }

    heading {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 17px;
      /* 19 */
      font-weight: 600
        /* 1000 */
    }

    hr {
      border: 0;
      height: 1px;
      background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }

    strong {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 600
        /* 800 */
    }

    strongred {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      color: 'red';
      font-size: 16px
    }

    sectionheading {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 22px;
      font-weight: 600
    }

    pageheading {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 38px;
      font-weight: 400
    }

    .ImageBorder {
      border-width: 1px;
      border-color: Black;
    }

    span.highlight {
      background-color: #ffffd0;
    }

    table {
      max-width: 840;
    }

    .tag {
      padding-right: 2px;
    }
  </style>

  <link rel="shortcut icon" href="assets/images/site_logo.png">
  <script type="text/javascript" src="assets/js/hidebib.js"></script>
  <title>Aneesh Shetty</title>
  <meta name="Aneesh Shetty" http-equiv="Content-Type" content="Aneesh Shetty">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic'
    rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
    integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css" rel="stylesheet"
    type='text/css' crossorigin="anonymous">

  <!-- Start : Google Analytics Code -->
  <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date(); a = s.createElement(o),
        m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-64069893-1', 'auto');
    ga('send', 'pageview');
  </script>
  <!-- End : Google Analytics Code -->

  <!-- Scramble Script by Jeff Donahue -->
  <script src="assets/js/scramble.js"></script>
</head>

<body>
  <table border="0" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <p align="center">
            <pageheading>Aneesh Shetty</pageheading><br>
          </p>

          <tr>
            <td width="32%" valign="top">
              <div>
                <a href="assets/images/aneesh_shetty.jpg" target="_blank"><img src="assets/images/aneesh_shetty.jpg"
                    width="100%" style="border-radius:20px"></a>
              </div>
              <div align="center" style="padding-top:10px;"></div>
                <a id="icon_email" class="tag had" href="mailto:aneeshks@utexas.edu" target="_blank" style="margin: 0 7px;"><i class="fas fa-envelope"></i></a>
                <a id="icon_cv" class="tag had" href="assets/pdfs/resume.pdf" target="_blank" style="margin: 0 7px;"><i class="had fas fa-file-alt"></i></a>
                <a id="icon_github" class="tag had" href="https://github.com/aneeshk1412" target="_blank" style="margin: 0 7px;"><i class="had fab fa-github"></i></a>
                <a id="icon_linkedin" class="tag had" href="https://www.linkedin.com/in/aneeshkshetty/" target="_blank" style="margin: 0 7px;"><i class="fab fa-linkedin-in"></i></a>
                <a id="icon_gscholar" class="tag had" href="https://scholar.google.com/citations?user=IFPhHjAAAAAJ" target="_blank" style="margin: 0 7px;"><i class="fab fa-google"></i></a>
                <a id="icon_twitter" class="tag had" href="https://twitter.com/aneeshk1412" target="_blank" style="margin: 0 7px;"><i class="fab fa-twitter"></i></a>
              </div>
            </td>

            <td width="68%" valign="center" align="justify">
              <p>
                I like building efficient systems that solve complex math problems.
                I like math that reveals interesting structures.
                I like abstractions that are elegant and simplify complex problems.
                And I like to write code that make these things go brrr.
              </p>
            </td>
          </tr>
        </table>

        <hr />

                      <!-- <p>
                I am currently working on implementing codegen and RAG workflows for interesting system tasks at Annapurna Labs at Amazon.
                I also worked on our benchmark orchestrator across AWS services for benchmarking Graviton processor and other architectures at scale.
              </p>
              <p>
                Previously, I worked at Adobe in the Document Cloud Team as a Software Engineer, where I worked on
                their Core C++ Library for PDF, optimizing it for integration with Microsoft Edge.
              </p>
              <p>
                I completed my Bachelors in Computer Science from IIT Bombay, where I worked with Prof. Krishna S. on
                research in Multi-pushdown systems and Graph Monoids, and with Prof. Abir De on Active Data Subset selection for Regression.
              </p> -->

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td>
              <sectionheading>&nbsp;&nbsp;Updates</sectionheading>
              <div style="padding-top:10px;"></div>
              <div style="height:100px;overflow:auto;">
                <table width="95%" align="center" border="0">
                  <col width="100px">
                  <tr>
                    <td><b>Sep 2024</b></td>
                    <td>Our work on Finetuning using Singular Vectors was accepted at NeuRIPS 2024</td>
                  </tr>
                  <tr>
                    <td><b>May 2024</b></td>
                    <td>I will be joining Amazon as a Software Development Engineer in Annapurna Labs</td>
                  </tr>
                  <tr>
                    <td><b>May 2023</b></td>
                    <td>I will be joining Amazon as a Software Development Engineering Intern this Summer</td>
                  </tr>
                  <tr>
                    <td><b>Aug 2022</b></td>
                    <td>I will be working with Prof. Isil Dillig and Prof. Joydeep Biswas as a GRA at UT Austin</td>
                  </tr>
                  <tr>
                    <td><b>Aug 2022</b></td>
                    <td>I will be starting my MS in Computer Science at UT Austin</td>
                  </tr>
                  <tr>
                    <td><b>Aug 2021</b></td>
                    <td>Presented our work on Scope-Bounded Reachability in Valence Systems at CONCUR 2021</td>
                  </tr>
                  <tr>
                    <td><b>Aug 2021</b></td>
                    <td>Graduate from IIT Bombay with a B.Tech in Computer Science and Minor in Statistics</td>
                  </tr>
                  <tr>
                    <td><b>Jul 2021</b></td>
                    <td>I will be joining Adobe as a Software Engineer, working on their Core C++ PDF Library</td>
                  </tr>
                  <tr>
                    <td><b>Jun 2021</b></td>
                    <td>Our work on Scope-Bounded Reachability in Valence Systems was accepted at CONCUR 2021</td>
                  </tr>
                  <tr>
                    <td><b>Aug 2020</b></td>
                    <td>I started working as a Teaching Assistant for Automata Theory with Prof. Akshay S.</td>
                  </tr>
                </table>
              </div>
            </td>
          </tr>
        </table>

        <hr />

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td>
              <sectionheading>&nbsp;&nbsp;Publications</sectionheading>
              <!-- (representative papers are <span class="highlight">highlighted</span>) -->
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">

            <tr>
            <td width="33%" valign="top" align="center">
              <a href="https://neurips.cc/virtual/2024/poster/93272/">
              <img src="assets/images/svft.png" alt="svft" width="90%"
                style="padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black">
              </a>
            </td>
            <td width="67%" valign="top">
              <p>
              <a href="https://neurips.cc/virtual/2024/poster/93272/" id="SVFT"></a>
                <heading>SVFT: Parameter-Efficient Fine-Tuning with Singular Vectors</heading>
              </a>
              <br>
              Aneesh Shetty, Vijay Chandra Lingam, Atula Neerkaje, Aditya Vavre, Gautham Krishna Gudur, Joydeep Ghosh, Eunsol Choi, Alex Dimakis, Aleksandar Bojchevski, Sujay Sanghavi
              <br>
              NeurIPS 2024
              <br>
              </p>

              <div class="paper" id="svft">
              <a href="https://neurips.cc/virtual/2024/poster/93272/">[webpage]</a>
              <a href="javascript:toggleblock('svft-abs')">[abstract]</a>
              <a shape="rect" href="javascript:togglebib('svft')" class="togglebib">[bibtex]</a>
              <a href="https://arxiv.org/abs/2405.19597v1">[arXiv]</a>

              <p align="justify"> <i style="display: none;" id="svft-abs">
                Popular parameter-efficient fine-tuning (PEFT) methods, such as LoRA and its variants, freeze pre-trained model weights <math alttext="\mathbf{W}" class="ltx_Math" display="inline" id="id14.1.m1.1"><semantics id="id14.1.m1.1a"><mi id="id14.1.m1.1.1" xref="id14.1.m1.1.1.cmml">𝐖</mi><annotation-xml encoding="MathML-Content" id="id14.1.m1.1b"><ci id="id14.1.m1.1.1.cmml" xref="id14.1.m1.1.1">𝐖</ci></annotation-xml><annotation encoding="application/x-tex" id="id14.1.m1.1c">\mathbf{W}</annotation><annotation encoding="application/x-llamapun" id="id14.1.m1.1d">bold_W</annotation></semantics></math> and inject learnable matrices <math alttext="\mathbf{\Delta W}" class="ltx_Math" display="inline" id="id15.2.m2.1"><semantics id="id15.2.m2.1a"><mrow id="id15.2.m2.1.1" xref="id15.2.m2.1.1.cmml"><mi id="id15.2.m2.1.1.2" xref="id15.2.m2.1.1.2.cmml">𝚫</mi><mo id="id15.2.m2.1.1.1" xref="id15.2.m2.1.1.1.cmml">⁢</mo><mi id="id15.2.m2.1.1.3" xref="id15.2.m2.1.1.3.cmml">𝐖</mi></mrow><annotation-xml encoding="MathML-Content" id="id15.2.m2.1b"><apply id="id15.2.m2.1.1.cmml" xref="id15.2.m2.1.1"><times id="id15.2.m2.1.1.1.cmml" xref="id15.2.m2.1.1.1"></times><ci id="id15.2.m2.1.1.2.cmml" xref="id15.2.m2.1.1.2">𝚫</ci><ci id="id15.2.m2.1.1.3.cmml" xref="id15.2.m2.1.1.3">𝐖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id15.2.m2.1c">\mathbf{\Delta W}</annotation><annotation encoding="application/x-llamapun" id="id15.2.m2.1d">bold_Δ bold_W</annotation></semantics></math>.
                These <math alttext="\mathbf{\Delta W}" class="ltx_Math" display="inline" id="id16.3.m3.1"><semantics id="id16.3.m3.1a"><mrow id="id16.3.m3.1.1" xref="id16.3.m3.1.1.cmml"><mi id="id16.3.m3.1.1.2" xref="id16.3.m3.1.1.2.cmml">𝚫</mi><mo id="id16.3.m3.1.1.1" xref="id16.3.m3.1.1.1.cmml">⁢</mo><mi id="id16.3.m3.1.1.3" xref="id16.3.m3.1.1.3.cmml">𝐖</mi></mrow><annotation-xml encoding="MathML-Content" id="id16.3.m3.1b"><apply id="id16.3.m3.1.1.cmml" xref="id16.3.m3.1.1"><times id="id16.3.m3.1.1.1.cmml" xref="id16.3.m3.1.1.1"></times><ci id="id16.3.m3.1.1.2.cmml" xref="id16.3.m3.1.1.2">𝚫</ci><ci id="id16.3.m3.1.1.3.cmml" xref="id16.3.m3.1.1.3">𝐖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id16.3.m3.1c">\mathbf{\Delta W}</annotation><annotation encoding="application/x-llamapun" id="id16.3.m3.1d">bold_Δ bold_W</annotation></semantics></math> matrices are structured for efficient parameterization, often using techniques like low-rank approximations or scaling vectors.
                However, these methods typically show a performance gap compared to full fine-tuning.
                Although recent PEFT methods have narrowed this gap, they do so at the cost of additional learnable parameters.
                We propose <span class="ltx_text ltx_font_smallcaps" id="id19.6.1">SVFT</span>, a <span class="ltx_text ltx_font_italic" id="id19.6.2">simple</span> approach that fundamentally differs from existing methods: the structure imposed on <math alttext="\mathbf{\Delta W}" class="ltx_Math" display="inline" id="id17.4.m4.1"><semantics id="id17.4.m4.1a"><mrow id="id17.4.m4.1.1" xref="id17.4.m4.1.1.cmml"><mi id="id17.4.m4.1.1.2" xref="id17.4.m4.1.1.2.cmml">𝚫</mi><mo id="id17.4.m4.1.1.1" xref="id17.4.m4.1.1.1.cmml">⁢</mo><mi id="id17.4.m4.1.1.3" xref="id17.4.m4.1.1.3.cmml">𝐖</mi></mrow><annotation-xml encoding="MathML-Content" id="id17.4.m4.1b"><apply id="id17.4.m4.1.1.cmml" xref="id17.4.m4.1.1"><times id="id17.4.m4.1.1.1.cmml" xref="id17.4.m4.1.1.1"></times><ci id="id17.4.m4.1.1.2.cmml" xref="id17.4.m4.1.1.2">𝚫</ci><ci id="id17.4.m4.1.1.3.cmml" xref="id17.4.m4.1.1.3">𝐖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id17.4.m4.1c">\mathbf{\Delta W}</annotation><annotation encoding="application/x-llamapun" id="id17.4.m4.1d">bold_Δ bold_W</annotation></semantics></math> depends on the specific weight matrix <math alttext="\mathbf{W}" class="ltx_Math" display="inline" id="id18.5.m5.1"><semantics id="id18.5.m5.1a"><mi id="id18.5.m5.1.1" xref="id18.5.m5.1.1.cmml">𝐖</mi><annotation-xml encoding="MathML-Content" id="id18.5.m5.1b"><ci id="id18.5.m5.1.1.cmml" xref="id18.5.m5.1.1">𝐖</ci></annotation-xml><annotation encoding="application/x-tex" id="id18.5.m5.1c">\mathbf{W}</annotation><annotation encoding="application/x-llamapun" id="id18.5.m5.1d">bold_W</annotation></semantics></math>.
                Specifically, <span class="ltx_text ltx_font_smallcaps" id="id19.6.3">SVFT</span> updates <math alttext="\mathbf{W}" class="ltx_Math" display="inline" id="id19.6.m6.1"><semantics id="id19.6.m6.1a"><mi id="id19.6.m6.1.1" xref="id19.6.m6.1.1.cmml">𝐖</mi><annotation-xml encoding="MathML-Content" id="id19.6.m6.1b"><ci id="id19.6.m6.1.1.cmml" xref="id19.6.m6.1.1">𝐖</ci></annotation-xml><annotation encoding="application/x-tex" id="id19.6.m6.1c">\mathbf{W}</annotation><annotation encoding="application/x-llamapun" id="id19.6.m6.1d">bold_W</annotation></semantics></math> as a sparse combination of outer products of its singular vectors, training only the coefficients (scales) of these sparse combinations.
                This approach allows fine-grained control over expressivity through the number of coefficients.
                Extensive experiments on language and vision benchmarks show that <span class="ltx_text ltx_font_smallcaps" id="id19.6.4">SVFT<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote1.1.1.1">1</span></span><span class="ltx_text ltx_font_upright" id="footnote1.5">code is available at </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="https://github.com/VijayLingam95/SVFT/" title="">https://github.com/VijayLingam95/SVFT/</a></span></span></span></span> recovers up to <span class="ltx_text ltx_font_bold" id="id19.6.5">96%</span> of full fine-tuning performance while training only <span class="ltx_text ltx_font_bold" id="id19.6.6">0.006 to 0.25</span>% of parameters, outperforming existing methods that only recover up to <span class="ltx_text ltx_font_bold" id="id19.6.7">85%</span> performance using <span class="ltx_text ltx_font_bold" id="id19.6.8">0.03 to 0.8%</span> of the trainable parameter budget.
              </i></p>

              <pre xml:space="preserve" style="display:none; word-wrap: break-word;">
                @inproceedings{NEURIPS2024_48c368f1,
                  author = {Lingam, Vijay Chandra and Neerkaje, Atula and Vavre, Aditya and Shetty, Aneesh and Gudur, Gautham Krishna and Ghosh, Joydeep and Choi, Eunsol and Dimakis, Alex and Bojchevski, Aleksandar and Sanghavi, Sujay},
                  booktitle = {Advances in Neural Information Processing Systems},
                  editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
                  pages = {41425--41446},
                  publisher = {Curran Associates, Inc.},
                  title = {SVFT: Parameter-Efficient Fine-Tuning with Singular Vectors},
                  url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/48c368f105e8145b945227b73255635a-Paper-Conference.pdf},
                  volume = {37},
                  year = {2024}
                }
              </pre>
              </div>
            </td>
            </tr>


            <tr>
              <td width="33%" valign="top" align="center">
                <a href="https://drops.dagstuhl.de/opus/volltexte/2021/14406/">
                  <img src="assets/images/scope-bounded-reachability.png" alt="sym" width="90%"
                    style="padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black">
                </a>
              </td>
              <td width="67%" valign="top">
                <p>
                  <a href="https://drops.dagstuhl.de/opus/volltexte/2021/14406/" id="SCOPE-BOUNDED-REACHABILITY">
                    <heading>Scope-bounded Reachability in Valence Systems</heading>
                  </a>
                  <br>
                  Aneesh Shetty, Krishna S., Georg Zetzsche
                  <br>
                  CONCUR 2021
                  <br>
                </p>

                <div class="paper" id="scope-bounded-reachability">
                  <a href="https://drops.dagstuhl.de/opus/volltexte/2021/14406/">[webpage]</a>
                  <a href="javascript:toggleblock('scope-bounded-reachability-abs')">[abstract]</a>
                  <a shape="rect" href="javascript:togglebib('scope-bounded-reachability')" class="togglebib">[bibtex]</a>
                  <a href="https://arxiv.org/abs/2108.00963v1">[arXiv]</a>

                  <p align="justify"> <i style="display: none;" id="scope-bounded-reachability-abs">Multi-pushdown
                      systems
                      are a standard model for concurrent recursive programs, but they have an undecidable reachability
                      problem. Therefore, there have been several proposals to underapproximate their sets of runs so
                      that
                      reachability in this underapproximation becomes decidable. One such underapproximation that covers
                      a
                      relatively high portion of runs is scope boundedness. In such a run, after each push to stack i,
                      the
                      corresponding pop operation must come within a bounded number of visits to stack i.
                      In this work, we generalize this approach to a large class of infinite-state systems. For this, we
                      consider the model of valence systems, which consist of a finite-state control and an
                      infinite-state
                      storage mechanism that is specified by a finite undirected graph. This framework captures
                      pushdowns,
                      vector addition systems, integer vector addition systems, and combinations thereof. For this
                      framework, we propose a notion of scope boundedness that coincides with the classical notion when
                      the
                      storage mechanism happens to be a multi-pushdown.
                      We show that with this notion, reachability can be decided in PSPACE for every storage mechanism
                      in
                      the framework. Moreover, we describe the full complexity landscape of this problem across all
                      storage
                      mechanisms, both in the case of (i) the scope bound being given as input and (ii) for fixed scope
                      bounds. Finally, we provide an almost complete description of the complexity landscape if even a
                      description of the storage mechanism is part of the input.</i></p>

                  <pre xml:space="preserve" style="display:none;">
    @misc{shetty2021scopebounded,
      title={Scope-Bounded Reachability in Valence Systems},
      author={Aneesh K. Shetty and S. Krishna and Georg Zetzsche},
      year={2021},
      eprint={2108.00963},
      archivePrefix={arXiv},
      primaryClass={cs.FL}
    }
      </pre>
                </div>
              </td>
            </tr>

        </table>

        <hr />

        <table width="100%" align="center" border="0" cellpadding="10">
          <tr>
            <td>
              <sectionheading>&nbsp;&nbsp;Projects</sectionheading>
              <div style="padding-top:10px;"></div>
              <ul>
                <li>
                  <b>Automatic Visual Question Generation and Answering for Image Descriptions</b>: We used LLM as
                  question generator and VQA model as answerer to produce substantially descriptive paragraphs for
                  images,
                  and ground the generated questions using Image Segmentation.
                  <br>
                  <a href="assets/pdfs/nlp_project_report.pdf" target="_blank">[report]</a>
                </li>
                <li>
                  <b>GNN: A Survey on Architectures and Optimization:</b> We wrote a term paper on different GNN
                  architectures and various optimzations to speed them up.
                  <br>
                  <a href="assets/pdfs/compilers_term_paper.pdf" target="_blank">[report]</a>
                </li>
                <li>
                  <b>Optimizing cp -r:</b> We used io_uring released in Linux 5.1 to wrote a faster implementation of cp
                  -r.
                  <br>
                  <a href="assets/pdfs/advanced_os_project_report.pdf" target="_blank">[report]</a>
                </li>
              </ul>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="2">
          <tr>
            <td><br>
              <p align="right">
                <font size="1.5">
                  Template credits: <a href="https://www.cs.cmu.edu/~dpathak/" target="_blank">Deepak Pathak</a>
                </font>
              </p>
            </td>
          </tr>
        </table>

      </td>
    </tr>
  </table>

  <script xml:space="preserve" language="JavaScript">
    hideallbibs();
  </script>

</body>

</html>